TensorForce-Client - Running Parallelized Reinforcement Learning Experiments in the Cloud
=========================================================================================

TensorForce-Client is an easy to use command line interface to the open source
reinforcement learning (RL) library TensorForce. This client helps you to setup
and run your own RL experiments in the cloud (only google supported so far),
utilizing GPUs, multi-parallel execution algorithms, and TensorForce's support for
a large variety of environments ranging from simple gridworlds to Atari games and
Unreal Engine 4 games.


.. toctree::
   :maxdepth: 2
   :caption: Contents:

   tensorforce_client/tensorforce_client.installation
   tensorforce_client/tensorforce_client


More information
----------------

You can find more information at our `TensorForce-Client GitHub repository <https://github.com/reinforceio/TensorForce-Client>`__.

For the core TensorForce library, visit: `<https://github.com/reinforceio/TensorForce>`__.

We also have a seperate repository available for benchmarking our algorithm implementations
[here](https://github.com/reinforceio/tensorforce-benchmark).
